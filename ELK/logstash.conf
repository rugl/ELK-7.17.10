input {
  tcp {
    mode => "server" #指定為 server 模式
    host => "0.0.0.0" #server 模式時, IP 為本機
    port => 5044 #指定 port 號
    codec => json_lines #指定輸入資料的解碼器 使用 json格式
    type => info #日志類型
  }
}

filter {
  # Optional - add filters to structure and enrich your data
  mutate {
    add_tag => ["logstash"]
    #Remove the `_jsonparsefailure` and `_grokparsefailure` tags, if they are present
    remove_tag => ["_jsonparsefailure", "_grokparsefailure"]
    add_field => {
      "environment" => "development"
    }
  }
  json{
      source => "message"
      target => "parsed_json"
      skip_on_invalid_json => true
   }

  # group start 
  # grok {
  #       match => {
  #           "message" => "\[INFO\s+\]\s+%{TIMESTAMP_ISO8601} %{DATA} - %{GREEDYDATA:extracted_message}"
  #       }
  #       tag_on_failure => []  # Prevents adding _grokparsefailure tag on failure
  #       # match => { "log" => "\[%{DATA:textColor}%{LOGLEVEL:logLevel} %{NOTSPACE:notSpace}\[%{DATA:textColor}\[%{MONTHNUM:month}-%{MONTHDAY:day}\|%{TIME:HHmmss}\|%{GREEDYDATA:logPath}\] %{GREEDYDATA:logContext}  %{GREEDYDATA:keyPairs}" }
  #   }
  # # Replace the original message with the cleaned-up extracted content
  # mutate {
  #   replace => { "message" => "%{extracted_message}" }
  # }
  # group end

}

output {
  elasticsearch {
    # hosts => ["http://elasticsearch:9200"]
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
    retry_on_conflict => 5
    action => "index"
    timeout => 120
  }
  stdout { 
    codec => rubydebug #可以在 logstash 的控制台輸出日志, 默認為 rubydebug
  }
}
